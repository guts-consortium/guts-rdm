[
  {
    "objectID": "metadata.html#guts",
    "href": "metadata.html#guts",
    "title": "8  Metadata",
    "section": "8.1 GUTS",
    "text": "8.1 GUTS\nThe way that data is structured within GUTS results in metadata being present in three different ways.\n\nIn the name of the file (file naming conventions can be found here)\nIn the folder location\nIn an accompanying file (e.g. a .JSON file)\n\nThe table below presents an overview of all data types and where their metadata can be found.\n\n\n\n\n\n\n\n\n\n\n\nData source\n\nData Type\nMetadata\nMetadata format\n\n\nEEG data\nBioSemi Data Format (.bdf)\nCan be found in the name of the file (e.g. sub-guts-eur-001_ses-01_task-name.bdf), or in the folder location (e.g. data/sub-guts0001/eeg/*, meaning a file regarding the anatomical scans), or in an accompanying file with the same name as the original file (e.g. sub-guts-eur-001_ses-01_task-name.json)\nFilename, folder location, .json file\n\n\nEEG tasks\nE-Prime experiment file (.ebs)\n*\n*\n\n\nEEG behavioral data\nTabular (.tsv)\nCan be found in the name of the file (e.g. xxx), or in an accompanying file with the same name (e.g. xxx).\nFilename, .json file\n\n\nMRI scans\nNIfTI files (.nii.gz)\nCan be found in the name of the file (e.g. sub-guts-eur-001_ses-01_inplaneT2.nii.gz), or in the folder location (e.g. data/sub-guts0001/anat/*, meaning a file regarding the anatomical scans), or in an accompanying file with the same name as the original file (e.g. sub-guts-eur-001_ses-01_inplaneT2.json)\nFilename, folder location, .json file\n\n\nfMRI tasks\nE-Prime/OpenSesame/Presentation\n*\n*\n\n\nfMRI behavioral data\nNIfTI files (.nii.gz)\nCan be found in the name of the file (e.g. sub-guts-eur-001_ses-01_task-name_bold.nii.gz or task-name_events.tsv), or in the folder location (e.g. data/sub-guts0001/func/*, meaning a file regarding the functional scans), or in an accompanying file with the same name as the original file (e.g. sub-guts-eur-001_ses-01_task-name_bold.json)\nFilename, folder location, .json file\n\n\nESM\nTabular (.tsv)\nCan be found in the name of the file (e.g. sub-guts-eur-001_ses-01_esmday01.tsv), or in an accompanying file with the same name (e.g. sub-guts0001_ses-1_esmday01.json).\nFilename, .json file\n\n\nQuestionnaires\nTabular (.tsv)\nCan be found in the name of the file (e.g. aiss.tsv), or in an accompanying file with the same name (e.g. aiss.json).\nFilename, .json file\n\n\nHormonal data\nTabular (.tsv)\nCan be found in the accompanying file (e.g. x.tsv), or in an accompanying file with the same name (e.g. x.json).\nFilename, .json file\n\n\n\n\nHow to create this metadata will be eplained in the page How to convert your data to Yoda standards"
  },
  {
    "objectID": "metadata.html#metadata-explorer",
    "href": "metadata.html#metadata-explorer",
    "title": "8  Metadata",
    "section": "8.2 Metadata Explorer",
    "text": "8.2 Metadata Explorer\nMetadata is shown in the GUTS metadata explorer (currently a prototype version) and is divided in the following ways:\n\nGeneral overview of the data including waves and general description.\nParticipant information including N, number of dropouts and other general participant information per wave.\nMeasure overview including measure name, category, description and type per measure and wave.\n\nThis explorer will include a search function to find and select variables required for your research. These variables along with certain preset filters (age, wave, gender, etc.) can then be made into a package which and be requested for analysis."
  },
  {
    "objectID": "data-collection.html",
    "href": "data-collection.html",
    "title": "Data collection",
    "section": "",
    "text": "In the following pages you can find more information about what is important during data collection for data management. We will discuss how to save your data in a harmonized way within the consortium. This means the use of specific data formats, metadata, and file names, and in the codebook we describe all variable names used in GUTS.\n\n\n\n\n\nData collection icons created by Becris - Flaticon\n\nChapters:\nGUTS overview\nGUTS codebook\nGUTS protocols\nData formats\nMetadata\nUploading to YODA"
  },
  {
    "objectID": "yoda-upload.html#local-yoda-web-portals-and-support",
    "href": "yoda-upload.html#local-yoda-web-portals-and-support",
    "title": "9  How to upload your GUTS data to Yoda",
    "section": "9.1 Local Yoda web portals and support",
    "text": "9.1 Local Yoda web portals and support\nFor each data collection location in GUTS there is a local Yoda portal that will be used to upload, store and archive your data. The table below shows which Yoda URL connects to which data collection location within the GUTS consortium and where to find your local Yoda support page.\n\nData location\n\n\n\n\nLocal Yoda url\nLocal Yoda support page\n\n\nWP1 Amsterdam-VU\nhttps://portal.yoda.vu.nl\nhttps://yoda.vu.nl/site/\n\n\nWP1 Rotterdam-EUR\nhttps://erasmus-yoda.irods.surfsara.nl/\nhttps://www.eur.nl/onderzoek/research-services/research-data-management/tooling/surf-yoda\n\n\nWP2 Leiden-UL\nhttps://leiden-yoda.irods.surfsara.nl/\nhttps://servicedesk.surf.nl/wiki/display/WIKI/Yoda+user+guide\n\n\nWP3 Amsterdam-AUMC\nhttps://aumc-yoda.irods.surfsara.nl/\nhttps://servicedesk.surf.nl/wiki/display/WIKI/Yoda+user+guide\n\n\nWP4 Utrecht-UU\nhttps://uu-yoda.irods.surfsara.nl/\nhttps://www.uu.nl/en/research/yoda/what-is-yoda\n\n\n\n\nYou can visit this page for general Yoda guidance provided by SURF."
  },
  {
    "objectID": "yoda-upload.html#requesting-yoda-workspace-and-uploading-to-yoda",
    "href": "yoda-upload.html#requesting-yoda-workspace-and-uploading-to-yoda",
    "title": "9  How to upload your GUTS data to Yoda",
    "section": "9.2 Requesting Yoda workspace and uploading to Yoda",
    "text": "9.2 Requesting Yoda workspace and uploading to Yoda\nIn the three steps below, we explain how you can request a personal workspace for Yoda, sign into that workspace and upload your data.\n\n\n\n\n\n\n1. Requesting Yoda workspace\n\n\n\n\n\nRequesting a Yoda workspace differs per location and is handled by each university differently. The most important thing is that the workspaces that will be created, for all data collected in a specific location, follow the same naming convention. In total four workspaces will be needed per location (two for the pilot and two for the main study), which are divided in the following ways:\n\nA distinction will be made between pilot data and main study data\nWithin these two categories, a distinction will be made between raw data and “up to guts standard” data\n\nRaw data is all the data you deposit immediately/as soon as possible after collection, unaltered.\nThe “up to guts standard” data includes data that is converted to the standard required to conduct research. More information on converting your data to GUTS standards can be found in the following chapter.\n\n\nAll workspaces within Yoda will start with the prefix research-. In the table below you will find the final names of the workspaces for each location. They follow these naming conventions:\n\nWorkspaces for the pilot will follow the convention: guts-pilot-[location] and then an added -raw for the raw data workspace\nWorkspaces for the main study will follow the convention: guts-[location] and then an added -raw for the raw data workspace\n\n\n\n\n\n\n\n\n\nData Location\nPilot workspace name\nMain study workspace name\n\n\nWP1 Amsterdam-VU\nresearch-guts-pilot-vu-raw\nresearch-guts-pilot-vu\nresearch-guts-vu-raw\nresearch-guts-vu\n\n\nWP1 Rotterdam-EUR\nresearch-guts-pilot-eur-raw\nresearch-guts-pilot-eur\nresearch-guts-eur-raw\nresearch-guts-eur\n\n\nWP2 Leiden-UL\nresearch-guts-pilot-lei-raw\nresearch-guts-pilot-lei\nresearch-guts-lei-raw\nresearch-guts-lei\n\n\nWP3 Amsterdam-AUMC\nresearch-guts-pilot-aumc-raw\nresearch-guts-pilot-aumc\nresearch-guts-aumc-raw\nresearch-guts-aumc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2. Yoda sign in\n\n\n\n\n\n\nIf you go to your local Yoda web portal you can find the “Sign in” button in the top right. This takes you to a page where you have to sign in with your institutional email (the same email you would use for other SURFconext or SRAM logins). NOTE: You are only able to sign in if you have been added to a workspace!\n\nThis sends you on to the SURFconext/SRAM sign in page.\n\n\n\n\n\n\n\n\n\n\n3. Uploading data\n\n\n\n\n\nAfter you have signed in you will find that the ‘Research’ and ‘Vault’ buttons have appeared in the top left of the screen.\n\nIf you requested a workspace using the same email address you used to sign in, or you have been added to that workspace, you can find it by clicking on Research on the Top left.\n\nIn this overview find your research folder (in this example “research-guts-dummy”).\n\nHere you can find the data that you have uploaded previously. We will highlight two major actions here and explain them in more detail later:\n\nUploading data: Using the “Upload” button in the top right, you can upload files/folders. You can also drag and drop files directly from your own system into the Yoda portal. There are also other options to upload data, like using curl. An example on using curl can be found in the following chapter. For more information regarding this example of using curl you can visit this page on github.\nFor large data uploads like MRI or EEG data there is a way to use curl to send the data to your Yoda workspace using a variation of the following command:\ncurl -u [yoda-emailadres] -T [bestand].zip https://[location]-data.irods.surfsara.nl/[research-projectnaam]\nGroup management: Using the “Go to group manager” button in the top right, you invite members (if you are the group manager, which you are if you requested the workspace) and give different permissions to members (read/write rights etc.)."
  },
  {
    "objectID": "processing-data.html",
    "href": "processing-data.html",
    "title": "Data processing",
    "section": "",
    "text": "In the following pages you can find more information about what is important during data processing shortly after data is collected. We will discuss naming conventions used within the consortium and how to save your data.\n\nChapters:\nNaming conventions\nSpecific naming conventions\nData structure\nHow to save your data"
  },
  {
    "objectID": "general-naming-conventions.html",
    "href": "general-naming-conventions.html",
    "title": "11  Naming conventions",
    "section": "",
    "text": "Good and structured file names will help you and your collaborators to easily navigate the content and status of files in your project. Within the GUTS consortium we use file naming conventions from the Brain Imaging Data Structure (BIDS) for MRI and related files. For all other files, we suggest the following best practices:\nIn general, good file names are (see also Klapwijk (2023)):\n\nMachine-readable:\n\n\nUse not much more than letters, numbers, hyphens and underscores. Avoid spaces, punctuation, accented characters, and case sensitivity\n\nFor example, paper_flanker-task_draft01.docx is preferred over paper “flanker task” draft01(1).docx\n\nDeliberately use delimiters. Use a hyphen (-) to mean “different words that are part of the same chunk”, and underscore (_) to separate different chunks of metadata\n\nFor example, file names in the BIDS specification nicely follow this principle: the file sub-01_ses-02_task-feedback_run-01.nii contains instances of the “subject”, “ses(sion)”, “task” an “run” entities, making it evident from the filename alone that it contains the nii (nifti) feedback task data for run 01 from session 02 of subject 01\n\n\n\nHuman-readable:\n\n\n\nGood file names provide useful clues to the content, status and version of a file, uniquely identify a file and help in classifying and sorting files\nChoose keywords and file names that are sufficiently descriptive, e.g., analysis01_descriptive-statistics.R,analysis02_preregistered-analysis.R\n\n\n\nMake sorting and searching easy:\n\n\n\nUse YYYY-MM-DD date format (ISO 8601 standard)\nTo order files put date or number first, e.g., 2019-01-01_original-analysis.R, 2019-12-01_minor-changes-to-original.R, 01_original-analysis.R, 02_minor-changes-to-original.R\nInclude the version of the file, e.g., methodology-section _v1\n\n\n\n\n\n\n\n\nKlapwijk, Eduard. 2023. “Best Practices for Documenting and Organizing Research Projects,” January. https://doi.org/10.5281/ZENODO.7551576."
  },
  {
    "objectID": "specific-naming-conventions.html",
    "href": "specific-naming-conventions.html",
    "title": "12  Specific naming conventions",
    "section": "",
    "text": "As mentioned in the general naming conventions section, naming should be both human as well as machine readable. Most of this can be solved by using BIDS as explained in the previous section, however there are some GUTS-specific naming conventions that need to be adhered to.\n\n\n\n\n\n\nMeasures\n\n\n\n\n\nTo comply with the machine-readable requirement, processed measure file names should always include \"_task-[short name]_\". The short name of a measure, as specified in the codebook, should be used to ensure each collection site uses the same measure name. For example, the Interpersonal Reactivity Index (IRI) has been given the short name “iri”. Its file name should therefore always include \"_task-iri_\". It is crucial that the short names match the ones in the codebook, as our scripts specifically search for these names.\n\n\n\n\n\n\n\n\n\nSessions\n\n\n\n\n\nSessions will be named according to the BIDS standard, meaning that they start with 'ses-'.\nCohorts A, B, D are scheduled to collect data in year 2, 5 and 8 of the ten-year GUTS project. Their respective sessions will be named 'ses-01', 'ses-02', 'ses-03'.\nCohort D, in addition to the regular sessions, will collect data between session 1 and 2, and between session 2 and 3: `ses-01a', 'ses-02a'.\nCohort C plans to collect data twice a year in year 2 and 3. The first sessions of a year will be named 'ses-01', 'ses-02', while the second measurements, taking place six months after the first measurement, will be labeled `ses-01a', 'ses-02a'.\nPilot\nThe pilot sessions will be named 'ses-pilot'\n\n\n\n\n\n\n\n\n\nSubject IDs\n\n\n\n\n\nThe subject ID naming convention varies slightly for each data storage location. To prevent accidental overlap between collected data from different cohorts, an abbreviation of the location will be added to each subject ID, as illustrated below.\nGiven that approximately 400-800 subjects will participate at each location, we advise to use a number between 0 and 800. The subject id number should always consist of three digits, e.g., subject 1 will be assigned the number 001, subject 15 will receive the number 015.\n\n\n\n\n\n\n\n\n\nData storage location\nSubject ID naming convention\nExample\n\n\n\n\nErasmus University Rotterdam (EUR)\nsub-guts-eur-#\nsub-guts-eur-001\n\n\nLeiden University (LEI)\nsub-guts-lei-#\nsub-guts-lei-001\n\n\nVrije Universiteit Amsterdam (VU)\nsub-guts-vu-#\nsub-guts-vu-001\n\n\nAmsterdam UMC (AUMC)\nsub-guts-aumc-#\nsub-guts-aumc-001\n\n\n\n\nSubject IDs pilot\nDuring the pilot, 'pilot' will be added to the subject ID: 'sub-guts-pilot-[location]-#'.\n\n\n\n\n\n\n\n\n\nFile names\n\n\n\n\n\nTo prevent duplicate file names, it is essential that for each data storage location to add their abbreviation to the file name. For participant-level files, such as brain imaging data, the location will be integrated into the subject ID in the file name. For group-level files, the location must be added separately. Additionally, file names should consistently include the session and task, as outlined earlier.\nParticipant-level (individual) files: sub-[subjectid]_ses-[session]_task-[short-name].\nGroup-level files (all participants merged): guts-[location]_ses-[session]_task-[short-name].\nRaw vs processed files\nUltimately, it is crucial that the processed files strictly follow the correct naming conventions to ensure our scripts can be executed properly. However, future you will be grateful if the raw output also adheres to a clear and consistent naming convention, as this will facilitate data processing.\nTherefore, when setting up a task (e.g., (f)MRI, EEG, E-Prime, Dynanometer, etc.) and if possible, please ensure adherence to the naming conventions by filling in subject names/session/task names. Note that for some measures (e.g., MRI), the option to fully decide on output file naming might not be available beforehand.\nBelow you can find some examples.\n\n\n\n\n\n\n\n\n\n\n\nType\nRaw\nRaw naming conventions\nProcessed\nProcessed naming conventions\n\n\n\n\nQualtrics - GUTS wide\n.sav\n2024-02-26_guts-lei_ses-02_quests-guts-wide_raw.sav\n.tsv\nguts-lei_ses-02_task-iri.tsv\nguts-lei_ses-02_task-ypi.tsv\n\n\nQualtrics - Cohort specific\n.sav\n2024-02-26_guts-lei_ses-02_quests-guts-specific_raw.sav\n.tsv\nguts-lei_ses-02_task-iri.tsv\nguts-lei_ses-02_task-ypi.tsv\n\n\nESM\n.csv\n2024-02-26_guts-eur_ses-01_esm_raw.csv/sub-guts-eur-001_ses-01_esm_raw.csv\n.tsv\nguts-eur_ses-01_task-esm-pressure.tsv\n\n\n(f)MRI\n.nii\nsub-guts-eur-014_ses-03_task-fmri-sddt_run-01_raw.nii\n.nii\nsub-guts-eur-014_ses-03_task-fmri-sddt_run-01.nii\n\n\n\n.par\nsub-guts-eur-014_ses-03_task-fmri-sddt_run-01_raw.par\n-\n\n\n\n\n.rec\nsub-guts-eur-014_ses-03_task-fmri-sddt_run-01_raw.rec\n-\n\n\n\nEEG\n.bdf\nsub-guts-eur-027_ses-01_task-eeg-social-flanker_raw.bdf\n.bdf\nsub-guts-eur-027_ses-01_task-eeg-social-flanker.bdf\n\n\nDynanometer\n.csv?\nsub-guts-eur-028_ses-03_task-dyno-prosocial-effort_raw.csv\n.tsv\nguts-eur_ses-03_task-dyno-prosocial-effort.tsv\n\n\nBehavioral\n.edat3\nsub-guts-vu-002_ses-02_task-sddt_raw.edat3\n.tsv\nguts-vu_ses-02_task-sddt.tsv\n\n\n\n.txt\nsub-guts-vu-002_ses-02_task-sddt_raw.txt\n-\n-\n\n\nPhysiological\nlabels\nsub-guts-aumc-005_ses-01_task-saliva-testo_t0\nsub-guts-aumc-007_ses-01_task-saliva-testo_t30\n.tsv\nguts-aumc_ses-01_task-saliva-testo.tsv\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariables\n\n\n\n\n\nFor measures, involving tabular data, collected across multiple cohorts, the variable names must be harmonized. This harmonization allows us to easily merge the files belonging to a specific measure from various data storage locations into one file. To facilitate this, we propose the naming convention below. Please collaborate with representatives from overlapping cohorts to ensure uniformity in variable names. For measures with no overlap, the use of specific naming conventions is less crucial. However, we still recommend using a consistent naming pattern, such as the examples provided below.\ns[session]_[shortname]_[subpart-task]_q/t0[question/trial #]\n\nNames: lowercase letters with all distinct information separated by an_underscore\nLabels: Full sentences starting with a capital letter.\nValue labels: lowercase letters\n\nThe variable and value labels can be added to an SPSS file and later converted to a .tsv file + .json file, or manually incorporated into a .json file directly. For more information on creating .json files, see Chapter 15. Below are examples of variable names:\n*Note that hyphens/dashes are not allowed in SPSS and should therefore not be used in variable names.\n\n\n\n\n\n\n\n\n\nVariable name\nVariable label\nValue labels\n\n\n\n\ns02_iri_pt_q03\nInterpersonal Reactivity Index - Perspective taking scale Q3: I sometimes find it difficult to see things from the other guy’s point of view.\n0 = does not describe me very well, 4 = described me very well\n\n\ns02_dailyhassles_freq_q04\nParenting Daily Hassles scale - Frequency Q4: The kids won’t listen or do what they are asked without being nagged.\n1 = never, 2 = rarely, 3 = sometimes, 4 = often, 5 = constantly\n\n\ns03_pcg_exb1_perc_to2\nProsocial Cyberball Task - Exclusion Block 1: Percentage of throws to player 2.\n\n\n\ns03_ddmoney_ind_day180\nDelay Discounting Money: Indifference point day 180: Prefer to receive this amount of money now than 10 euros in 180 days.\n\n\n\ns03_salivacort_d1_m1\nSaliva Samples -Cortisol: Mean cortisol in nmol/l day 1, measurement 1."
  },
  {
    "objectID": "data-structure.html",
    "href": "data-structure.html",
    "title": "13  Data structure",
    "section": "",
    "text": "GUTS’ data structure will be based on BIDS principles, with some small adjustments to ensure a logical workflow. Below you can find a preliminary version of the intended GUTS data structure for processed files."
  },
  {
    "objectID": "why-rdm.html",
    "href": "why-rdm.html",
    "title": "Why invest in RDM?",
    "section": "",
    "text": "The first part of this handbook provides background on why it is important to invest time and resources in Research Data Management in a project like GUTS.\n\nChapters:\nThe benefits of good RDM\nFAIR data\nData management planning"
  },
  {
    "objectID": "benefits-rdm.html#research-data-management",
    "href": "benefits-rdm.html#research-data-management",
    "title": "1  The benefits of good RDM",
    "section": "1.1 Research data management",
    "text": "1.1 Research data management\nResearch Data Management (RDM) considers the organisation, storage and preservation of data created during a research project. It covers a wide range of activities such as initial planning, day-to-day processes and long-term archiving and sharing. This means that the list of benefits of doing this well is quite extensive as well.\nHere we provide a non-exhaustive list of benefits:\n\n\nproper data storage and backup prevents data loss\nmaking data understandable for others (and your future self) allows reuse and collaboration\nproper data management is key to Open Science, since transparency and reuse of data is only possible using well-documented data\ngood RDM also helps to prevent misconduct since it allows you to show the integrity of the data collection process\nit makes research go more smoothly, allowing you as a researcher to focus on the problems of science rather than data administravia (Briney, Coates, and Goben 2020)"
  },
  {
    "objectID": "benefits-rdm.html#data-management-in-guts",
    "href": "benefits-rdm.html#data-management-in-guts",
    "title": "1  The benefits of good RDM",
    "section": "1.2 Data management in GUTS",
    "text": "1.2 Data management in GUTS\nIn the GUTS project, data will be collected from different longitudinal cohorts at different locations in the Netherlands. This will encompass magnetic resonance imaging (MRI) data, questionnaire data (e.g. behavioral and social measures), and genetic data. A number of similar measures will be collected across all cohorts. This RDM Handbook and all other efforts to streamline the organization of the data within the GUTS consortium is all aimed to make working with this data as seamless as possible.\nOpen Science and collaboration are very important pillars of the GUTS project. Good data management is vital to facilitate collaboration within the consortium, and eventually also with researchers outside the consortium.\nWe are planning to use a “FAIR from the start” approach, which means that we are striving to unify data collection and data processing from the start. This will allow us to build a database including a metadata explorer that shows the data in various ways. In this way, once the data is collected and processed, it can be unlocked by researchers to analyse it thoroughly and safely.\n\n\n\n\nBriney, Kristin, Heather Coates, and Abigail Goben. 2020. “Foundational Practices of Research Data Management.” Research Ideas and Outcomes 6 (July): e56508. https://doi.org/10.3897/rio.6.e56508."
  },
  {
    "objectID": "fair-data.html#findable",
    "href": "fair-data.html#findable",
    "title": "2  FAIR data",
    "section": "2.1 Findable",
    "text": "2.1 Findable\nMetadata and data should be easy to find for both humans and computers. In the GUTS consortium, we plan to add machine-readable metadata from the start. Data is stored on SURF Yoda storage, a research data management system that facilitates and enforces adding structured metadata to your research data. More information about metadata standards can be found in the pages about metadata and GUTS standards."
  },
  {
    "objectID": "fair-data.html#accessible",
    "href": "fair-data.html#accessible",
    "title": "2  FAIR data",
    "section": "2.2 Accessible",
    "text": "2.2 Accessible\nIn practice, this means that potential users of the data need to know how the data can be accessed. This does not mean that data should always be open or free. Given the sensitive nature of much of the GUTS data, the plan is in a later stage of the project to make the data available under strict access conditions to other researchers. For accessibility, we will clearly specify the conditions and procedure for access."
  },
  {
    "objectID": "fair-data.html#interoperable",
    "href": "fair-data.html#interoperable",
    "title": "2  FAIR data",
    "section": "2.3 Interoperable",
    "text": "2.3 Interoperable\nInteroperability is about how data integrates with other data and with tools for analysis, storage, and processing. The practical steps we take within GUTS is using open file formats for data, community standards for metadata, and publishing a GUTS schema to describe the data. These steps allow for a “common understanding” of digital objects for both humans and machines."
  },
  {
    "objectID": "fair-data.html#reusable",
    "href": "fair-data.html#reusable",
    "title": "2  FAIR data",
    "section": "2.4 Reusable",
    "text": "2.4 Reusable\nTo cite the Go FAIR website:\n\nThe ultimate goal of FAIR is to optimise the reuse of data. To achieve this, metadata and data should be well-described so that they can be replicated and/or combined in different settings.\n\nIn the GUTS consortium, we try to achieve this by richly describing the context under which the data was generated. For example, for MRI data we use the BIDS standard in which imaging data is accompanied by machine-readable metadata in sidecar JSON files."
  },
  {
    "objectID": "planning.html",
    "href": "planning.html",
    "title": "3  Data management planning",
    "section": "",
    "text": "In a Data Management Plan (DMP), a description is given on and how the data will be collected, stored, shared and managed, and by who. Questions that will be answered in a DMP cover every part of the research cycle, including legal arrangements, storage solutions, data sharing possibilities etc.\nThe initial overall GUTS DMP was written in September 2022 and approved by NWO. We will update the plan regularly.\nFor specific GUTS projects, the project leads should write a project-specific DMP with more detail about how data will be handled within their project. We are planning to write guidelines for specific projects once the overall data management structure for GUTS is in place (Summer 2024)."
  },
  {
    "objectID": "protocols.html",
    "href": "protocols.html",
    "title": "6  GUTS protocols",
    "section": "",
    "text": "In the future, you’ll be able to find all protocols here. These protocols will take you through all the steps taken before, during, and after data collection."
  },
  {
    "objectID": "how-to-save-your-data.html",
    "href": "how-to-save-your-data.html",
    "title": "14  How to convert your data to GUTS standards",
    "section": "",
    "text": "This chapter has been written in order to ensure that all GUTS data can be considered as one massive dataset, by having all sites convert their data in the same way. The following data types will be covered:\n\n\n\nQuestionnaires\n(f)MRI\nEEG\nBehavioral data\nPhysiological data (e.g., ecg, skin conductance, dynanometer output)\nESM\nHormone and Genetic data\n\n\n\nPicture: Data Conversion / xkcd / CC BY-NC 2.5\n\n\n\n\n\n\n\n\nQuestionnaire data\n\n\n\n\n\nStep 1.\nDownload the raw data from qualtrics as a .sav and rename the file to DATE_gutscohortlocation_raw.sav (e.g. 20231211_guts-eur_raw.sav). The extension .sav is used to ensure that Qualtrics gives the right output, as .csv or .tsv sometimes gives faulty output. The cleaned file will not be a .sav file.\nMake a copy of this file and store it in a secure folder. This way you have one file that stays as raw data and another you can clean using this handbook as a guide.\nStep 2.\nOpen up Rstudio and create a new RProject, by going to file -&gt; create new project. Select Existing Directory and navigate to the secure folder where you stored the raw data. Create a new .R file, by going to File -&gt; new file -&gt; R script. Name this file appropriately (e.g. guts-eur_questionnaire_cleaning) and save it in the same folder.\nStep 3.\nThis will begin the R coding side of the data cleaning. A template of the final R script will be provided. Open up your R file and load up the haven and tidyverse libraries by typing:\n#load in necessary libraries\nlibrary(haven)\nlibrary(tidyverse)\nand press SHIFT+Enter (if you haven’t installed these libraries yet, write the following line into the console below and press Enter)\ninstall.packages('haven')\ninstall.packages('tidyverse')\nLoad in the raw dataset:\n#load in necessary libraries\nlibrary(haven)\nlibrary(tidyverse)\n\n#load in raw dataset\nguts_raw &lt;- read.sav(\"20231211_guts-eur_raw.sav\")\nStep 4.\nAll variables that give unnecessary (e.g. startdate, duration in seconds) or sensitive information (e.g. LocationLongitude/Latitude) must be removed. These unwanted variables are present in column 1:9 and 14:17. Remove them and reorder the columns so that the ExternalReference (which is usefull to the participant id) is the first column. You can do this by adding the following lines to your script:\n#subset of relevant columns and reorder\nguts_raw &lt;- guts_raw[,c(13,10:12,18:685)]\nMake sure that these variable numbers line up with your raw data file, they may differ from this example. The variables that should remain are:\n\nExternalReference\nRecipientLastName\nRecipientFirstName\nRecipientEmail\nDemographic variables, including Date of Birth, Age, sex, gender, …. all the way to SES variables (around column 118)\nAll research questionnaire data (the rest of the questionnaire).\n\nNote: the name and email variables, together with the ExternalReference/participant id will be transferred to a separate file (and stored separately from the data) in a later stage, to serve as a contact list for future waves and payment.\nStep 5.\nMake sure that all duplicates are removed and that if both entries have the same amount of progress, only the last entry should remain. Also remove all entries without data, this includes entries that only provided demographic data but did not respond to any questionnaire.\nAll data coming in from Qualtrics will have to be pseudoanonymized. Make sure to remove any directly identifying information including:\n……….\n\n\n\n\n\n\n\n\n\n(f)MRI data\n\n\n\n\n\nRaw output from (f)MRI data might differ between locations, e.g., only DICOM files or .nii, .par and .rec files. Bidsifying (organizing and naming of files according to the BIDS standard), however, should happen in a similar way for all outputs. There are several programs one can use to bidsify data to limit manual labor. See the BIDS website for more information about options. Please refer to Chapter 12. Specific naming conventions and Chapter 13. Data structure while BIDSyfing. After BIDSifying, a pipeline (fMRI Prep/HALFpipe) can be used for further (pre-)processing. A pipeline is currently being developed and will be shared once finished.\n\nExample of a prebidsified and a bidsified data structure\n\n\n\n\n\n\n\n\n\nEEG data\n\n\n\n\n\nRaw output from EEG data might differ between locations depending on programs/materials used. However, BIDSified data should end up looking the same. There are several ways in which EEG data can be automatically BIDSified. (see the BIDS website). After BIDSifying, a pipeline can be used for further (pre-)processing. This pipeline is currently being developed and will be shared once finished.\n\n\n\n\n\n\n\n\n\nBehavioral tasks\n\n\n\n\n\nBehavioral tasks can yield data from tasks during EEG, ECG, (f)MRI, Dynamometer, but also from tasks conducted solely on a computer/e-prime without being linked to any sort of biological/physiological information. For all behavioral tasks, a group-level file has to be created so that group analyses can be performed based on all participants’ scores, for example. Additionally, individual files of behavioral tasks will be processed and relocated according to BIDS to facilitate individual analyses.\n\n\n\n\n\n\n\n\n\nPhysiological data\n\n\n\n\n\nPhysiological data could include ECG data, skin conductance data, and grip force data (dynamometer). The raw output will differ depending on the programs/materials used. Nonetheless, all output should be BIDSified (named and located according to BIDS standards) before further (pre-)processing.\n\n\n\n\n\n\n\n\n\nESM data\n\n\n\n\n\nESM data will be processed similarly to the Qualtrics questionnaire data.\n\n\n\n\n\n\n\n\n\nBiological and Genetic data\n\n\n\n\n\nHair and saliva samples will be send to a lab for analysis. After analysis, you will receive files that should be processed to adhere to the guts standard."
  },
  {
    "objectID": "glossary.html#sec-a",
    "href": "glossary.html#sec-a",
    "title": "Glossary",
    "section": "A",
    "text": "A\nAccessible\nOne of the FAIR principles: Once a user finds the required data, they need to know how data can be accessed, possibly including authentication and authorisation."
  },
  {
    "objectID": "glossary.html#sec-b",
    "href": "glossary.html#sec-b",
    "title": "Glossary",
    "section": "B",
    "text": "B\nBIDS\nBIDS is the Brain Imaging Data Structure. The specification is intentionally based on simple file formats and folder structures to reflect current lab practices and make it accessible to a wide range of scientists coming from different backgrounds."
  },
  {
    "objectID": "glossary.html#sec-g",
    "href": "glossary.html#sec-g",
    "title": "Glossary",
    "section": "G",
    "text": "G\nGUTS\nThe GUTS (Growing Up Together in Society) consortium investigates youth from the perspective of societal neuroscience, and combines insights and expertise from neuroscience, psychology, psychiatry, and sociology. The consortium is funded by a Gravitation grant from the Ministry of Education, Culture and Science for a ten-year period (2023-2033). To learn more about GUTS visit the GUTS consortium website"
  },
  {
    "objectID": "glossary.html#sec-r",
    "href": "glossary.html#sec-r",
    "title": "Glossary",
    "section": "R",
    "text": "R\nResearch Data Management\nResearch Data Management (RDM) considers the organisation, storage and preservation of data created during a research project. It covers a wide range of activities such as initial planning, day-to-day processes and long-term archiving and sharing."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Briney, Kristin, Heather Coates, and Abigail Goben. 2020.\n“Foundational Practices of Research Data Management.”\nResearch Ideas and Outcomes 6 (July): e56508. https://doi.org/10.3897/rio.6.e56508.\n\n\nKlapwijk, Eduard. 2023. “Best Practices for Documenting and\nOrganizing Research Projects,” January. https://doi.org/10.5281/ZENODO.7551576."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GUTS RDM Handbook",
    "section": "",
    "text": "Welcome\nThis is the website for the Research Data Management (RDM) Handbook of the Growing Up Together in Society (GUTS) consortium.\nThe goal of the GUTS RDM Handbook is to bring everything about data collection, data management, and data handling in the GUTS consortium together in a central and easily searchable place. First and foremost, the goal is to facilitate data management within the GUTS consortium. Second, we hope that this handbook might be useful for other projects. We are building upon resources and wisdom of many others, we hope to pay it forward by making this resource openly available.\nThe GUTS consortium investigates youth from the perspective of societal neuroscience, and combines insights and expertise from neuroscience, psychology, psychiatry, and sociology. The consortium is funded by a Gravitation grant from the Ministry of Education, Culture and Science for a ten-year period (2023-2033). To learn more about GUTS visit https://www.gutsproject.com/."
  },
  {
    "objectID": "codebook.html",
    "href": "codebook.html",
    "title": "5  GUTS codebook",
    "section": "",
    "text": "Here you can find a preliminary version of all GUTS measures. For now, you can find an overview of which measures are collected by which cohort(s). Later, you will be able to find more information about the measures, the items, the labels and levels, etc. Note that measures may still be changed."
  },
  {
    "objectID": "data-formats.html",
    "href": "data-formats.html",
    "title": "7  Data formats",
    "section": "",
    "text": "The GUTS project follows a multi-method, multi-index approach. As a result, the GUTS data consists of various data types and formats. Below you can find an overview of all data types and formats during the two phases of data processing.\n\nRaw data\nThe raw files are defined as the files that have not been through any processing. For example, the files that are exported from e-prime, qualtrics, mri, etc.\n\n\n\n\n\n\n\nData type\nData format\n\n\n\n\nQualtrics questionnaire\n.csv or .sav\n\n\nDemographics\n.csv or .sav\n\n\nBehavioral\n.csv, .xlsx, .edat3\n\n\nEEG\n.bdf\n\n\nEEG behavioral\n.csv\n\n\n(f)MRI\n.PAR + .REC + .nii or .dcm\n\n\n(f)MRI behavioral\neprime: .edat3, opensesame:, presentations:\n\n\nESM\n.csv or .tsv\n\n\nPhysiological measures\nphysical saliva and hair samples\n\n\n\n\n\nProcessed data\nThe processed files are the fully-cleaned files after all steps of processing. The processed files are uploaded to Yoda.\n\n\n\n\n\n\n\nData type\nData format\n\n\n\n\nQualtrics questionnaire\n.tsv\n\n\nDemographics\n.tsv\n\n\nBehavioral\n.tsv\n\n\nEEG\n.bdf (bidsified with BIDScoiner)\n\n\nEEG behavioral\n.tsv\n\n\n(f)MRI\n.nii conversion files: inplane and w\n\n\n(f)MRI behavioral\n.tsv\n\n\nESM\n.tsv\n\n\nPhysiological measures\n.tsv"
  },
  {
    "objectID": "processing-documentation.html",
    "href": "processing-documentation.html",
    "title": "10  Documentation",
    "section": "",
    "text": "When working with data, it is crucial that you document the manner in which data will be used (preregistration) and that you keep track of all adjustments made while processing data.\nThis not only ensures transparency about the manner in which the data was used but is also beneficial to researchers. To illustrate, when in the future questions arise about a published article (e.g., analyses), documented steps can be easily retraced to provide answers and/or locate potential mishaps. Additionally, proper documentation facilitates replication as all necessary steps are documented. Your documentation will be part of your publication package.\n\n\n\n\n\n\nSome tips\n\n\n\n\n\n\nStart early and document while you are working with the data. Do not wait until after your project is finished to try and trace back what happened while processing and analyzing data.\nScript (R, SPSS, Python, Matlab, etc) what you can and add clear comments to your code. If something crashes and/or a file gets lost, your adjustments to the data can be rerun and no adjustments get lost. Additionally, other researchers get a clear insight in your data processing.\nKeep log files. You can use these files to document discrepancies in data, reason for missing/non-valid data, problems that were encountered (and how they were fixed), etc.\n\n\n\n\nPregistration & Publication package\nFor each paper or publication, you will be creating a preregistration and a publication package. Preregistrations will be published on the GUTS OSF page, where you will also find some preregistration templates. Guidelines may vary per institution, but a preregistration typically includes:\n\n\n\nBasic metadata (e.g. title, description, study information, etc.)\nYour research plan (e.g. study type, randomization, etc.)\nSampling\nVariables\nAnalysis plan (e.g. statistical models, data exclusion, etc.)\nOther information (e.g. cited literature)\n\n\n\nPublication packages can also be published on the GUTS OSF page, or you can choose a different site based on your institution’s guidelines. However, it’s crucial to note that data will not be shared on the OSF page or any other site apart from Yoda. Although guidelines may vary between institutions, a publication package will typically contain the following:\n\n\n\nA published manuscript.\nUsed tasks and questionnaires.\nRaw data.\nComputer code.\nProcessed data files.\nSupplementary information.\nAn approved ethics protocol.\n\n\n\n\n\n\n\n\n\nComing soon: Guidelines per institute"
  },
  {
    "objectID": "codebook-dash.html",
    "href": "codebook-dash.html",
    "title": "6  GUTS codebook",
    "section": "",
    "text": "Here you can find a preliminary version of all GUTS measures. For now, you can find an overview of which measures are collected by which cohort(s). Later, you will be able to find more information about the measures, the items, the labels and levels, etc. Note that measures may still be changed."
  },
  {
    "objectID": "how-to-add-metadata.html",
    "href": "how-to-add-metadata.html",
    "title": "15  How to add metadata to your data",
    "section": "",
    "text": "15.0.1 JSON files\nEach processed data file will be accompanied by a Javascript Object Notation (JSON) file that contains information about the content of the file. JSON files can be made in basic programs such as Notepad, but also Visual Studio Code, Jupyter Notebook, etc. When using Notepad just make sure to save your file under data types ‘all files’ and add the JSON file extension .json.\n\n\n\n\n\n\nTabular data\nTSV files do not retain information regarding variable labels, values and value labels. Therefore, a JSON file will be created to ensure no information gets lost. This JSON file can then be used to facilitate analyses, by merging the variable information into the data.\nBelow you can find examples of what a JSON file could look like. You could also add information, such as task description, references, etc.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestionnaire\nBehavioral task\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncreate-json-file script. Tabular doesn’t automatically get a JSON file. Therefore, we provide you with a script you can run to create basic json files (and .tsv files) from .sav files. [link]\n*If your data consists of .csv/.xlsx/.tsv files, you could still use the script but there won’t be any variable information in the JSON output as this is non-existent in the original file.\nYou could opt to convert the non .sav files to .sav files first and add variable and value information there and then run the script on the .sav files, or you could run the script on the non .sav files and add variable/value information to the output JSON file manually.\n\n\n\n\n\n\n\n\n\n\n\n\nNon-tabular data\nWhen bidsifying non-tabular data, such as (f)MRI/EEG files, JSON files should be automatically created. They contain information about echo time, slice timing, repetition time, (eeg) coordinates, and information about the scanner for example. In addition, you could manually add any other relevant information, such as task name or task description if not included in the output. There may also be information in the automatically created JSON file that isn’t crucial, you could opt to leave this out of the file.\n\n\n\n\n\n\n\n\n(f)MRI\nEEG\nPhysiology\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYoda metadata forms\n\n\n\n\n\nComing soon"
  },
  {
    "objectID": "how-to-add-metadata.html#json-files",
    "href": "how-to-add-metadata.html#json-files",
    "title": "15  How to add metadata to your data",
    "section": "15.1 JSON files",
    "text": "15.1 JSON files\nEach processed data file will be accompanied by a Javascript Object Notation (JSON) file that contains information about the content of the file. JSON files can be made in basic programs such as Notepad, but also Visual Studio Code, Jupyter Notebook, etc. When using Notepad just make sure to save your file under data types ‘all files’ and add the JSON file extension .json.\n\n\n\n\n\n\nTabular data\nTSV files do not retain information regarding variable labels, values and value labels. Therefore, a JSON file will be created to ensure no information gets lost. This JSON file can then be used to facilitate analyses, by merging the variable information into the data.\nBelow you can find examples of what a JSON file could look like. You could also add information, such as task description, references, etc.\n\n\n\n\n\n\n\nQuestionnaire\nBehavioral task\n\n\n\n\n\n\n\n\n\n\nAutomate json creation. Tabular doesn’t automatically get a JSON file. Therefore, we provide you with a script you can run to create basic json files (and .tsv files) from .sav files. Click here to download a beta version of the script.\nIf your data consists of non-sav (.csv/.xlsx/.tsv) files, you could still use the script but there won’t be any variable information in the JSON output as this is non-existent in the original file. You could also opt to convert the non .sav files to .sav files first and add variable and value information there and then run the script on the .sav files, or you could run the script on the non .sav files and add variable/value information to the output JSON file manually.\n\n\n\n\n\n\n\n\n\n\nNon-tabular data\nWhen bidsifying non-tabular data, such as (f)MRI/EEG files, JSON files should be automatically created. They contain information about echo time, slice timing, repetition time, (eeg) coordinates, and information about the scanner for example. In addition, you could manually add any other relevant information, such as task name or task description if not included in the output. There may also be information in the automatically created JSON file that isn’t crucial, you could opt to leave this out of the file.\n\n\n\n\n\n\n\n\n(f)MRI\nEEG\nPhysiology"
  },
  {
    "objectID": "how-to-add-metadata.html#yoda-metadata-forms",
    "href": "how-to-add-metadata.html#yoda-metadata-forms",
    "title": "15  How to add metadata to your data",
    "section": "15.2 Yoda metadata forms",
    "text": "15.2 Yoda metadata forms\nComing soon"
  }
]